"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getMergedPatches = void 0;
const object_1 = require("../../core/object");
const patch_1 = require("./patch");
/**
 * A utility function that hasn't been moved in to the lucid-extension-sdk yet. It takes something that satisfies the
 * map interface, `mapLike`, and finds if `maplike` contains the existing key. If it does, it returns the key. If it
 * does not, it creates a new instance of the key value from the `fallback` function, adds it to the map, and then
 * returns that.
 *
 * @param mapLike The map-like object we are getting/setting on.
 * @param key The key we are looking up.
 * @param fallback A function with provides a default value for when the map doesn't have the given key.
 * @returns The value of the map at the given key, having created the entry in the map if it didn't already exist.
 */
function setIfNotPresentAndGet(mapLike, key, fallback) {
    const valIfPresent = mapLike.get(key);
    if (valIfPresent !== undefined) {
        return valIfPresent;
    }
    const newVal = fallback();
    mapLike.set(key, newVal);
    return newVal;
}
/**
 * Turn an array of raw moves into an equivalent set of connected chains. It also returns utility maps which track
 * which elements end up in the tail of which returned chains (`backMapping`) and which anchors each chain starts with,
 * `anchorMapping`.
 *
 * @param itemOrderChanged The original sequence of raw moves that we are consolidating into chains.
 * @returns an object containing the relevant chains and some lookup utility values. The contents of the response are:
 *
 * connectedChains: an array of chains representing the original reordering as described by the ConnectedChain type.
 * backMapping: An array from primary keys to the index of the chains that contain those keys in their tails. Note that
 *              the arrays are in reverse order, largest indexes first.
 * anchorMapping: An array from priamry keys to the index of the chains that have the key as their anchor. These are
 *                also in reverse order, largest indexes first.
 *
 */
function getConnectedChains(itemOrderChanged) {
    const connectedChains = [];
    const backMapping = new Map();
    const anchorMapping = new Map();
    let lastMoved = undefined;
    let currentTail = new Set();
    let currentAnchor = undefined;
    itemOrderChanged === null || itemOrderChanged === void 0 ? void 0 : itemOrderChanged.forEach(([moved, next]) => {
        if (lastMoved !== next) {
            if (currentAnchor !== undefined) {
                setIfNotPresentAndGet(anchorMapping, currentAnchor, () => []).unshift(connectedChains.length);
                connectedChains.push({
                    anchor: currentAnchor,
                    tail: currentTail,
                    anchorBlockers: new Set([...currentTail]
                        .filter((tailKey) => anchorMapping.has(tailKey))
                        .map((key) => { var _a, _b; return (_b = (_a = anchorMapping.get(key)) === null || _a === void 0 ? void 0 : _a[0]) !== null && _b !== void 0 ? _b : -1; })),
                });
            }
            currentAnchor = next;
            currentTail = new Set();
        }
        currentTail.add(moved);
        setIfNotPresentAndGet(backMapping, moved, () => []).unshift(connectedChains.length);
        lastMoved = moved;
    });
    if (lastMoved !== undefined) {
        if (currentAnchor !== undefined) {
            setIfNotPresentAndGet(anchorMapping, currentAnchor, () => []).unshift(connectedChains.length);
            connectedChains.push({
                anchor: currentAnchor,
                tail: currentTail,
                anchorBlockers: new Set([...currentTail]
                    .filter((tailKey) => anchorMapping.has(tailKey))
                    .map((key) => { var _a, _b; return (_b = (_a = anchorMapping.get(key)) === null || _a === void 0 ? void 0 : _a[0]) !== null && _b !== void 0 ? _b : -1; })),
            });
        }
    }
    return { connectedChains, backMapping, anchorMapping };
}
/**
 * Take an array of connected chains (plus auxillary maps for efficient access) and remove all possible moves involving
 * the given key. Note that if the key was used as an anchor for a chain somewhere, we can't delete references to it
 * from that chain or any chains before, because we don't necessarily know where the key was moved from when used as
 * an anchor.
 *
 * @param connectedChains The connected chains of the type returned from getConnectedChains
 * @param backMapping The map from the non-anchor elements of the chains to which chains they appear in in connected chains
 * @param anchorMapping The map from the anchor elements of the chains to the chains of which they are anchor
 *
 * @returns Doesn't explicitly return anything, but does modify all input parameters in place to do the expected
 * update.
 */
function trimChains(connectedChains, backMapping, anchorMapping, key) {
    var _a, _b, _c;
    const keyBarrier = (_b = (_a = anchorMapping.get(key)) === null || _a === void 0 ? void 0 : _a[0]) !== null && _b !== void 0 ? _b : -1;
    const backMappingList = (_c = backMapping.get(key)) !== null && _c !== void 0 ? _c : [];
    [...backMappingList].every((previousInstanceRow) => {
        if (previousInstanceRow < keyBarrier) {
            return false;
        }
        connectedChains[previousInstanceRow].tail.delete(key);
        backMappingList.shift();
        return true;
    });
}
/**
 * Our goal when combining moves is to minimize the number of chains produced. When we are adding new moves, we
 * thus first search for existing chains they can be inserted into. It sometimes happens that there is a target
 * chain that we can add the new move to, but that the new move cannot "reach" the target chain because one of the
 * intermediate chains block the insertion (the move operators do not commute and cannot be modified to have an
 * equivalent move). When that happens, it is sometimes possible to instead move the target chain down through the
 * list of chains to a location where the new move actually can be inserted correctly. This function is about moving
 * the chains around so that the insertion can be performed consistently, if possible.
 *
 *
 * @param connectedChains See the description on `getConnectedChains`.
 * @param backMapping See the description on `getConnectedChains`.
 * @param anchorMapping See the description on `getConnectedChains`.
 * @param mostRecentBlocker The index of the chain that stops the new move from being added.
 * @param targetIndex The index of the chain that we are trying to insert the new move into.
 * @returns An object containing the target index of the actual chain that we can insert the move into, if it exists. If
 * we can not insert the move into the original target, it returns undefined. Note that if `newTargetIndex` is different
 * from `targetIndex`, this function has changed `connectedChains`, `backMapping` and `anchorMapping` in place
 * in order to actually move the target.
 */
function rearrangeAroundBlockersIfPossible(connectedChains, backMapping, anchorMapping, mostRecentBlocker, targetIndex) {
    if (mostRecentBlocker <= targetIndex) {
        return { newTargetIndex: targetIndex };
    }
    if (targetIndex < 0 || targetIndex >= connectedChains.length) {
        return undefined;
    }
    let blocked = false;
    for (let i = targetIndex + 1; !blocked && i <= mostRecentBlocker; i++) {
        blocked = connectedChains[i].anchorBlockers.has(targetIndex);
    }
    if (blocked) {
        return undefined;
    }
    function indexMapper(index) {
        if (index < targetIndex || index > mostRecentBlocker) {
            return index;
        }
        if (index === targetIndex) {
            return mostRecentBlocker;
        }
        return index - 1;
    }
    connectedChains.forEach((chain) => {
        chain.anchorBlockers = new Set([...chain.anchorBlockers].map(indexMapper));
    });
    [...backMapping].forEach(([key, rows]) => {
        backMapping.set(key, rows.map(indexMapper));
    });
    [...anchorMapping].forEach(([anchorKey, rows]) => {
        anchorMapping.set(anchorKey, rows.map(indexMapper));
    });
    const targetRow = connectedChains.splice(targetIndex, 1)[0];
    connectedChains.splice(mostRecentBlocker, 0, targetRow);
    return { newTargetIndex: mostRecentBlocker };
}
/**
 * Function which modifies the chain information to add a new chain to the current list. Note this this aggresively
 * tries to combine a new chain with existing chains, if possible, but will add a new chain if necessary.
 *
 * @param connectedChains See the description on `getConnectedChains`.
 * @param backMapping See the description on `getConnectedChains`.
 * @param anchorMapping See the description on `getConnectedChains`.
 * @param anchor The anchor for the new chain.
 * @param chain The tail for the new chain.
 * @returns Nothing, but modifies `connectedChains`, `backMapping` and `anchorMapping` in place to incorporate the
 * new chain.
 */
function insertNewChain(connectedChains, backMapping, anchorMapping, anchor, chain) {
    var _a, _b, _c, _d;
    const anchorBlockers = new Set([...chain].filter((key) => anchorMapping.has(key)).map((key) => { var _a, _b; return (_b = (_a = anchorMapping.get(key)) === null || _a === void 0 ? void 0 : _a[0]) !== null && _b !== void 0 ? _b : -1; }));
    const anchorMergeTarget = (_b = (_a = anchorMapping.get(anchor)) === null || _a === void 0 ? void 0 : _a[0]) !== null && _b !== void 0 ? _b : -1;
    const nonAnchorMergeTarget = anchor !== null ? ((_d = (_c = backMapping.get(anchor)) === null || _c === void 0 ? void 0 : _c[0]) !== null && _d !== void 0 ? _d : -1) : -1;
    const targetIndex = Math.max(anchorMergeTarget, nonAnchorMergeTarget);
    const isAnchorTarget = targetIndex !== nonAnchorMergeTarget;
    const mostRecentBlocker = Math.max(...anchorBlockers);
    const newTargetIfPossible = rearrangeAroundBlockersIfPossible(connectedChains, backMapping, anchorMapping, mostRecentBlocker, targetIndex);
    function backLinkKeys(chain, index) {
        chain.forEach((chainKey) => setIfNotPresentAndGet(backMapping, chainKey, () => []).unshift(index));
    }
    if (!newTargetIfPossible || newTargetIfPossible.newTargetIndex < 0) {
        connectedChains.push({ anchor, tail: chain, anchorBlockers });
        const endingChainIndex = connectedChains.length - 1;
        setIfNotPresentAndGet(anchorMapping, anchor, () => []).unshift(endingChainIndex);
        backLinkKeys(chain, endingChainIndex);
        return;
    }
    const { newTargetIndex } = newTargetIfPossible;
    const newChain = isAnchorTarget ? new Set([...chain]) : new Set();
    const targetChain = connectedChains[newTargetIndex];
    targetChain.tail.forEach((chainKey) => {
        newChain.delete(chainKey);
        newChain.add(chainKey);
        if (!isAnchorTarget && chainKey === anchor) {
            chain.forEach((insertedKey) => {
                newChain.delete(insertedKey);
                newChain.add(insertedKey);
            });
        }
    });
    connectedChains[newTargetIndex].tail = newChain;
    backLinkKeys(newChain, newTargetIndex);
}
/**
 * This function takes an array of new item order moves and appends them to the end of the existing chains,
 * aggressively merging chains if possible.
 *
 * @param connectedChains See the description on `getConnectedChains`.
 * @param backMapping See the description on `getConnectedChains`.
 * @param anchorMapping See the description on `getConnectedChains`.
 * @param newItemOrderChanged The new set of moves from the new patch that we are adding it.
 * @returns Nothing, but modifies `connectedChains`, `backMapping` and `anchorMapping` in place to incorporate the
 * new moves.
 */
function mergeIntoChains(connectedChains, backMapping, anchorMapping, newItemOrderChanged) {
    var _a, _b;
    // Pop off the last available chain, because we need to continue to growth as thought it started up again clean
    // with the next item order. The logic changes are to account for the fact that keys might now be duplicated.
    const lastChain = connectedChains.pop();
    lastChain === null || lastChain === void 0 ? void 0 : lastChain.tail.forEach((keyInLastChain) => { var _a; return (_a = backMapping.get(keyInLastChain)) === null || _a === void 0 ? void 0 : _a.shift(); });
    (lastChain === null || lastChain === void 0 ? void 0 : lastChain.anchor) !== undefined && ((_a = anchorMapping.get(lastChain.anchor)) === null || _a === void 0 ? void 0 : _a.shift());
    let currentAnchor = lastChain === null || lastChain === void 0 ? void 0 : lastChain.anchor;
    let currentChain = (_b = lastChain === null || lastChain === void 0 ? void 0 : lastChain.tail) !== null && _b !== void 0 ? _b : new Set();
    let lastMoved = [...currentChain][currentChain.size - 1];
    newItemOrderChanged === null || newItemOrderChanged === void 0 ? void 0 : newItemOrderChanged.forEach(([key, pred]) => {
        if (lastMoved !== pred) {
            if (currentAnchor !== undefined) {
                insertNewChain(connectedChains, backMapping, anchorMapping, currentAnchor, currentChain);
            }
            currentAnchor = pred;
            currentChain = new Set();
        }
        if (key !== currentAnchor) {
            trimChains(connectedChains, backMapping, anchorMapping, key);
        }
        // Need to delete the key if it is already in the chain so that it gets moved to the end by the add, because
        // order matters.
        currentChain.delete(key);
        currentChain.add(key);
        lastMoved = key;
    });
    if (lastMoved !== undefined) {
        // Need to delete the key if it is already in the chain so that it gets moved to the end by the add, because
        // order matters.
        currentChain.delete(lastMoved);
        currentChain.add(lastMoved);
        if (currentAnchor !== undefined) {
            insertNewChain(connectedChains, backMapping, anchorMapping, currentAnchor, currentChain);
        }
    }
}
/**
 * Take an optional cumulative patch "patch up to this point" and combine it with the new patch this is being
 * applied.
 *
 * Note that this function assumes that the patches are both being applied to the exact same collection. We do
 * not validate that this is the case, and breaking that assumption could result in unexpected bad behavior. That
 * needs to have been checked or otherwise contrained by the calling code.
 *
 * @param cumulativePatch The previous patches merged in to a single patch up to this point
 * @param newPatch The new patches which are now being applied at this point
 * @returns The combined patch
 */
function getMergedPatches(prevCumulativePatch, newPatch) {
    if (prevCumulativePatch === undefined) {
        return newPatch;
    }
    // Copy the patch so we can change it in place
    const itemsDeleted = new Set(prevCumulativePatch.itemsDeleted);
    const itemsAdded = new Map(Object.entries(prevCumulativePatch.itemsAdded));
    const itemsChanged = new Map(Object.entries(prevCumulativePatch.itemsChanged));
    const { connectedChains, backMapping, anchorMapping } = getConnectedChains(prevCumulativePatch.itemOrderChanged);
    // Merge items changed in the new patch into the cumulative patch
    for (const [changedKey, changes] of Object.entries(newPatch.itemsChanged)) {
        if (itemsDeleted.has(changedKey)) {
            continue;
        }
        if (itemsAdded.has(changedKey)) {
            itemsAdded.set(changedKey, Object.assign(Object.assign({}, itemsAdded.get(changedKey)), changes));
        }
        else {
            itemsChanged.set(changedKey, Object.assign(Object.assign({}, itemsChanged.get(changedKey)), changes));
        }
    }
    // Add items added by the new patch to the cumulative patch
    for (const [addedKey, addedData] of Object.entries(newPatch.itemsAdded)) {
        itemsDeleted.delete(addedKey);
        itemsChanged.delete(addedKey);
        itemsAdded.set(addedKey, addedData);
    }
    mergeIntoChains(connectedChains, backMapping, anchorMapping, newPatch.itemOrderChanged);
    // Clear out any items deleted in upstream patches, or actively target pre-existing items for deletion
    const deletedItems = new Set(newPatch.itemsDeleted);
    for (const deletedKey of deletedItems) {
        if (itemsAdded.has(deletedKey)) {
            itemsAdded.delete(deletedKey);
        }
        else {
            itemsChanged.delete(deletedKey);
        }
        itemsDeleted.add(deletedKey);
        trimChains(connectedChains, backMapping, anchorMapping, deletedKey);
    }
    const itemOrderChanged = [];
    connectedChains.forEach(({ anchor, tail }) => {
        let lastNext = anchor;
        tail.forEach((chainEntry) => {
            if (!deletedItems.has(chainEntry)) {
                itemOrderChanged.push([chainEntry, lastNext]);
                lastNext = chainEntry;
            }
        });
    });
    return new patch_1.ItemPatch(prevCumulativePatch.id, (0, object_1.fromEntries)(itemsAdded), (0, object_1.fromEntries)(itemsChanged), [...itemsDeleted], itemOrderChanged.length === 0 ? undefined : itemOrderChanged, prevCumulativePatch.syncSourceId, prevCumulativePatch.syncCollectionId);
}
exports.getMergedPatches = getMergedPatches;
